# RAG-Based-Document-Query-System
 Retrieval-Augmented Generation (RAG) System using AWS Bedrock, LangChain, FAISS, and LLaMA 3
This project implements an end-to-end Retrieval-Augmented Generation (RAG) system for intelligent document querying and contextual answering. It leverages cutting-edge tools like AWS Bedrock, Titan Embeddings, LLaMA 3, FAISS, and LangChain to build a scalable and performant question-answering pipeline over custom document data.

ðŸ”§ Tech Stack
LLM: LLaMA 3

Embeddings: AWS Titan Embeddings

Vector Store: FAISS (Facebook AI Similarity Search)

Framework: LangChain

Frontend/UI: Streamlit

Orchestration: AWS Bedrock


ðŸš€ Features


âœ… Accepts user queries and retrieves relevant document chunks using semantic search

âœ… Uses Titan Embeddings to vectorize documents and store them in FAISS

âœ… Passes retrieved context into LLaMA 3 via LangChain RAG pipeline

âœ… Offers a clean, interactive interface via Streamlit

âœ… Easily extendable to support additional LLMs or embedding models via LangChain modularity

âœ… Hosted and orchestrated using AWS Bedrock for enterprise scalability

ðŸ“‚ Project Structure

â”œâ”€â”€ data                 # Dataset is uploaded here
â”œâ”€â”€ faiss_index          # Indexes are created and stored in vector store
â”œâ”€â”€ venv                 # Virtual Enviorment is created using this
â”œâ”€â”€ app.py               # Code is written in this portion 
â”œâ”€â”€ benchmarks.json      # Used for testing purpose
|â”€â”€ benchmark.py         # testing and graphs are made here
|â”€â”€ llama3.py            # llama3 model is invoked
â””â”€â”€ requiremets.txt      # all the libraries are installed using requirements
â””â”€â”€test.py               # to test the perfromance of the ap


Streamlit UI allowing users to query documents with real-time LLM-generated responses.

ðŸ“ˆ Use Cases
Internal document search and Q&A

Enterprise knowledge base assistance

Chatbot support over structured/unstructured data

Legal/Medical/Research paper summarization

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
Note: Requires AWS credentials with access to Bedrock APIs and LLaMA 3.

ðŸ“„ Future Improvements
Add support for multi-document ingestion and chunking

Integrate user feedback loop for continuous learning

Replace FAISS with scalable vector DB like Pinecone or Weaviate

Add authentication and role-based access to the Streamlit app
